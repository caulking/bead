# argument structure active learning configuration
#
# collects acceptability judgments on verb argument structure alternations
# using active learning until model performance converges to human agreement.
#
# design: full cross-product of verbs x frames to capture both grammatical
# and ungrammatical combinations.

# project metadata
project:
  name: "argument_structure"
  language_code: "eng"
  description: "Verb argument structure alternations with active learning"
  version: "0.1.0"
  authors:
    - "Aaron Steven White"

# paths
paths:
  data_dir: "."
  output_dir: "."
  cache_dir: ".cache"
  lexicons_dir: "lexicons"
  templates_dir: "templates"
  items_dir: "items"
  lists_dir: "lists"
  filled_templates_dir: "filled_templates"
  cross_product_items: "items/cross_product_items.jsonl"
  2afc_pairs: "items/2afc_pairs.jsonl"
  experiment_lists: "lists/experiment_lists.jsonl"

# resources
resources:
  lexicons:
    - path: "lexicons/verbnet_verbs.jsonl"
      name: "verbnet_verbs"
    - path: "lexicons/bleached_nouns.jsonl"
      name: "bleached_nouns"
    - path: "lexicons/bleached_verbs.jsonl"
      name: "bleached_verbs"
    - path: "lexicons/bleached_adjectives.jsonl"
      name: "bleached_adjectives"
    - path: "lexicons/prepositions.jsonl"
      name: "prepositions"
    - path: "lexicons/determiners.jsonl"
      name: "determiners"
    - path: "lexicons/be_forms.jsonl"
      name: "be_forms"

  templates:
    - path: "templates/generic_frames.jsonl"
      name: "generic_frames"

# template filling
template:
  filling_strategy: "mixed"  # exhaustive, mlm, or mixed
  output_path: "filled_templates/generic_frames_filled.jsonl"

  mlm:
    model_name: "bert-base-uncased"
    beam_size: 5
    top_k: 10
    device: "cpu"
    cache_enabled: true

  # slot strategies: exhaustive uses all lexicon entries; mlm selects top-N by probability
  # max_fills limits items per slot; enforce_unique prevents duplicates across beam hypotheses
  slot_strategies:
    # determiners: exhaustive (no mlm needed)
    det_subj: { strategy: "exhaustive" }
    det_dobj: { strategy: "exhaustive" }
    det_iobj: { strategy: "exhaustive" }
    det_pobj: { strategy: "exhaustive" }
    det_pobj2: { strategy: "exhaustive" }
    det_pobj3: { strategy: "exhaustive" }

    # be forms: exhaustive (agreement handled by constraints)
    be: { strategy: "exhaustive" }

    # main verb: exhaustive for full cross-product coverage
    verb: { strategy: "exhaustive" }

    # complement verbs: mlm
    comp_verb: { strategy: "mlm", max_fills: 5, enforce_unique: true }
    comp_verb_gerund: { strategy: "mlm", max_fills: 5, enforce_unique: true }

    # nouns: mlm with template constraints
    noun_subj: { strategy: "mlm", max_fills: 5, enforce_unique: true }
    noun_dobj: { strategy: "mlm", max_fills: 5, enforce_unique: true }
    noun_iobj: { strategy: "mlm", max_fills: 5, enforce_unique: true }
    noun_pobj: { strategy: "mlm", max_fills: 5, enforce_unique: true }
    noun_pobj2: { strategy: "mlm", max_fills: 5, enforce_unique: true }
    noun_pobj3: { strategy: "mlm", max_fills: 5, enforce_unique: true }
    subj: { strategy: "mlm", max_fills: 5, enforce_unique: true }
    comp_subj: { strategy: "mlm", max_fills: 5, enforce_unique: true }
    comp_obj: { strategy: "mlm", max_fills: 5, enforce_unique: true }
    recipient: { strategy: "mlm", max_fills: 5, enforce_unique: true }
    wh_noun: { strategy: "mlm", max_fills: 5, enforce_unique: true }

    # prepositions: mlm with template constraints
    prep: { strategy: "mlm", max_fills: 5, enforce_unique: true }
    prep2: { strategy: "mlm", max_fills: 5, enforce_unique: true }
    prep3: { strategy: "mlm", max_fills: 5, enforce_unique: true }

    # adjectives: mlm (unconstrained)
    adjective: { strategy: "mlm", beam_size: 3, max_fills: 5, enforce_unique: true }

# items
items:
  judgment_type: "forced_choice"
  n_alternatives: 2  # 2AFC

  models:
    - name: "gpt2"
      provider: "huggingface"
      device: "cpu"
      use_for_scoring: true

  construction:
    create_minimal_pairs: true
    pair_types:
      - "same_verb"       # same verb, different frames
      - "different_verb"  # different verbs, same frame
    score_filtering:
      enabled: true
      min_score_diff: 0.5  # minimum LM score difference for pairs

  preserve_metadata:
    - "verb_lemma"
    - "template_id"
    - "template_name"
    - "template_structure"
    - "pair_type"
    - "lm_score_diff"
    - "quantile"

# list partitioning
lists:
  strategy: "quantile_balanced_minimal_pairs"
  n_lists: 16
  items_per_list: 50
  quantile_bins: 10
  items_per_quantile: 10

  constraints:
    - type: "balance"
      property_expression: "item.metadata.pair_type"
      target_counts: { same_verb: 50, different_verb: 50 }

    - type: "uniqueness"
      property_expression: "item.metadata.get('verb1', item.metadata.get('verb'))"
      # no verb appears multiple times in same list

    - type: "grouped_quantile"
      property_expression: "item.metadata.lm_score_diff"
      group_by_expression: "item.metadata.pair_type"
      n_quantiles: 10
      items_per_quantile: 5

    - type: "diversity"
      property_expression: "item.metadata.template_id"
      min_unique_values: 15

  # batch constraints: apply across all lists
  batch_constraints:
    - type: "coverage"
      property_expression: "item['template_id']"
      target_values: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
      min_coverage: 1.0

    - type: "balance"
      property_expression: "item['pair_type']"
      target_distribution: { same_verb: 0.5, different_verb: 0.5 }
      tolerance: 0.05

    - type: "min_occurrence"
      property_expression: "item['quantile']"
      min_occurrences: 50

    - type: "diversity"
      property_expression: "item.get('verb1', item.get('verb'))"
      max_lists_per_value: 4  # spread verbs across lists

# training
training:
  convergence:
    metric: "krippendorff_alpha"  # or fleiss_kappa, cohens_kappa, percentage_agreement
    threshold: 0.05  # converged when |model_accuracy - human_agreement| < threshold
    min_iterations: 3
    alpha: 0.05  # significance level

  model:
    architecture: "transformer"
    model_name: "bert-base-uncased"
    learning_rate: 2e-5
    batch_size: 16
    epochs_per_iteration: 3
    warmup_steps: 100
    device: "cpu"

  data:
    validation_split: 0.2
    random_seed: 42
    balance_classes: true

# active learning
active_learning:
  strategy: "uncertainty_sampling"  # or query_by_committee, random
  method: "entropy"  # or least_confidence, margin
  budget_per_iteration: 200
  max_iterations: 20
  stopping_criterion: "convergence"  # or max_iterations, performance_threshold
  initial_training_size: 500
  batch_mode: true
  promote_diversity: true
  diversity_lambda: 0.1

# evaluation
evaluation:
  cross_validation:
    k_folds: 5
    stratify_by: "metadata.pair_type"
    shuffle: true
    random_seed: 42

  metrics: ["accuracy", "precision", "recall", "f1", "confusion_matrix"]

  interannotator:
    metrics: ["krippendorff_alpha", "fleiss_kappa", "percentage_agreement", "pairwise_agreement"]
    min_raters_per_item: 3

  tracking:
    save_checkpoints: true
    checkpoint_dir: "checkpoints"
    use_tensorboard: true
    log_dir: "logs"
    track_metrics: ["train_accuracy", "val_accuracy", "human_agreement", "convergence_gap"]

# deployment
deployment:
  platform: "jatos"  # or prolific, mturk

  # balanced assigns participants to least-used list
  distribution_strategy:
    strategy_type: "balanced"
    max_participants: 400
    error_on_exhaustion: false
    debug_mode: false
    debug_list_index: 0

  n_lists_to_deploy: 20
  random_seed: 42
  output_dir: "deployment"

  experiment:
    title: "Sentence Acceptability Judgments"
    description: "Rate which sentence sounds more natural"
    estimated_duration_minutes: 15

  jspsych:
    version: "8.0.0"
    use_jatos: true
    prolific_completion_code: null  # set when deploying to Prolific
    trial:
      type: "html-button-response"
      stimulus_duration: null
      trial_duration: null
    choices: ["Sentence A", "Sentence B"]
    randomize_order: true
    randomize_choices: true

  slopit:
    enabled: false
    keystroke: { enabled: true }
    focus: { enabled: true }
    paste: { enabled: true, prevent: false }
    target_selectors:
      forced_choice: ".bead-choice-button"

  participants:
    n_per_list: 30
    qualifications: ["Native English speaker", "Age 18+", "Approval rate > 95%"]
    payment_usd: 2.50
    bonus_usd: 0.50

  server:
    host: null
    port: 22
    username: null
    deploy_path: "/var/www/experiments"

# logging
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file:
    enabled: true
    path: "pipeline.log"
    max_bytes: 10485760  # 10 MB
    backup_count: 5
  console:
    enabled: true
    colored: true
